from ctypes import *
import pyrealsense2 as rs
import math
import random
import os
import cv2
import numpy as np
import time
import darknet
from datetime import datetime

def convertBack(x, y, w, h):
    xmin = int(round(x - (w / 2)))
    xmax = int(round(x + (w / 2)))
    ymin = int(round(y - (h / 2)))
    ymax = int(round(y + (h / 2)))
    return xmin, ymin, xmax, ymax


def cvDrawBoxes(detections, img):
    x = 240
    y = 320
    for label, confidence, bbox in detections:
        x, y, w, h = (bbox[0],
                      bbox[1],
                      bbox[2],
                      bbox[3])
        name_tag = label
        print(name_tag)
        xmin, ymin, xmax, ymax = convertBack(
            float(x), float(y), float(w), float(h))
        pt1 = (xmin, ymin)
        pt2 = (xmax, ymax)
        cv2.rectangle(img, pt1, pt2, (0, 255, 0), 1)
    # cv2.putText(img,
    # 			label +
    # 			" [" + str(confidence * 100, 2) + "]",
    # 			(pt1[0], pt1[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
    # 			[0, 255, 0], 2)
    return img, x, y


# netMain = None
# metaMain = None
network = None
class_names = None
class_colors = None
altNames = None


def YOLO(VideoWriter):
    try:
        global metaMain, netMain, altNames, network, class_names, class_colors, pipeline
        now = datetime.now()
        configPath = "./cfg/yolov3-tiny.cfg"
        weightPath = "./yolov3-tiny.weights"
        metaPath = "./cfg/coco.data"
        # configPath = "./cfg/yolov3-tiny-class6.cfg"
        # weightPath = "./yolov3-tiny-obj_899000.weights"
        # metaPath = "./build/darknet/x64/data/obj.data"
        if not os.path.exists(configPath):
            raise ValueError("Invalid config path `" +
                             os.path.abspath(configPath) + "`")
        if not os.path.exists(weightPath):
            raise ValueError("Invalid weight path `" +
                             os.path.abspath(weightPath) + "`")
        if not os.path.exists(metaPath):
            raise ValueError("Invalid data file path `" +
                             os.path.abspath(metaPath) + "`")
        if (network is None) and (class_names is None) and (class_colors is None):
            network, class_names, class_colors = darknet.load_network(configPath, metaPath, weightPath, batch_size=1)
        # if netMain is None:
        # 	netMain = darknet.load_net_custom(configPath.encode(
        # 		"ascii"), weightPath.encode("ascii"), 0, 1)  # batch size = 1
        # # print("1")
        # if metaMain is None:
        # 	metaMain = darknet.load_meta(metaPath.encode("ascii"))
        if altNames is None:
            try:
                with open(metaPath) as metaFH:
                    metaContents = metaFH.read()
                    import re
                    match = re.search("names *= *(.*)$", metaContents,
                                      re.IGNORECASE | re.MULTILINE)
                    if match:
                        result = match.group(1)
                    else:
                        result = None
                    try:
                        if os.path.exists(result):
                            with open(result) as namesFH:
                                namesList = namesFH.read().strip().split("\n")
                                altNames = [x.strip() for x in namesList]
                    except TypeError:
                        pass
            except Exception:
                pass

        pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)

        pipeline.start(config)

        # cap = cv2.VideoCapture(0)
        # cap = cv2.VideoCapture("test.mp4")
        # cap.set(3, 1280)
        # cap.set(4, 720)
        # out = cv2.VideoWriter(
        # 	"output.avi", cv2.VideoWriter_fourcc(*"MJPG"), 10.0,
        # 	(darknet.network_width(netMain), darknet.network_height(netMain)))
        print("Starting the YOLO loop...")

        # Create an image we reuse for each detect
        darknet_image = darknet.make_image(640,
                                           480, 3)
        x = 240
        y = 320
        while True:
            prev_time = time.time()
            # ret, frame_read = cap.read()

            frame_read = pipeline.wait_for_frames()
            depth_frame = frame_read.get_depth_frame()
            color_frame = frame_read.get_color_frame()
            if not depth_frame or not color_frame:
                continue
            depth_image = np.asanyarray(depth_frame.get_data())
            color_image = np.asanyarray(color_frame.get_data())
            depth_image = cv2.rotate(depth_image, cv2.ROTATE_180)  # rotate image
            color_image = cv2.rotate(color_image, cv2.ROTATE_180)  # rotate image
            print("depth_image" + str(depth_image.shape))
            print("color_image" + str(color_image.shape))
            # print(type(frame_read))#####################################################################
            frame_rgb = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)
            frame_resized = cv2.resize(frame_rgb,
                                       (640,
                                        480),
                                       interpolation=cv2.INTER_LINEAR)

            darknet.copy_image_from_bytes(darknet_image, frame_resized.tobytes())

            detections = darknet.detect_image(network, class_names, darknet_image, thresh=0.25)
            image, x, y = cvDrawBoxes(detections, frame_resized)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            print("image" + str(image.shape))
            print("center distance" + str(depth_image[240][320]))
            print("distance" + str(depth_frame.get_distance(int(x), int(y))))
            print(1 / (time.time() - prev_time))
            cv2.circle(image, (int(x), int(y)), 10, (0, 0, 255), -1)
            cv2.circle(image, (320, 240), 10, (0, 255, 255), 3)
            VideoWriter.write(image)
            # cv2.imshow('depth', depth_image)
            cv2.imshow('Demo', image)
            if cv2.waitKey(1) == ord("q"):
                 break
            frameTime = time.time() - prev_time
            print(1 / frameTime)
    finally:
        VideoWriter.release()
        # depthWriter.release()
        # pipeline.stop()

if __name__ == "__main__":
    now = datetime.now()
    current_time = now.strftime("%H_%M_%S")
    VideoPath = current_time + '_rgb.avi'
    VideoWriter = cv2.VideoWriter(VideoPath, cv2.VideoWriter_fourcc(*'XVID'), 30, (640, 480), 1)
    YOLO(VideoWriter)
